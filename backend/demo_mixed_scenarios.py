#!/usr/bin/env python3
"""
Mixed Confidence Scenarios Demo
Shows both auto-execution and human approval scenarios
"""
import json
import datetime
import os

class MixedSafetyDemo:
    """Demo with predefined scenarios showing different confidence levels"""
    
    def __init__(self):
        self.CONFIDENCE_THRESHOLD = 0.80
    
    def load_demo_scenarios(self):
        """Load scenarios from data file"""
        with open('../data/safety_demo_scenarios.json', 'r') as f:
            scenarios = json.load(f)
        
        # Add AI analysis based on expected confidence
        for scenario in scenarios:
            confidence = scenario['expected_confidence']
            if confidence >= 0.9:
                action = "load_balancing"
                reasoning = "Clear network congestion with high utilization and packet loss"
            elif confidence >= 0.8:
                action = "load_balancing"
                reasoning = "High confidence in congestion diagnosis and load balancing solution"
            elif confidence >= 0.6:
                action = "traffic_steering"
                reasoning = "Moderate issues but unclear root cause - more investigation needed"
            else:
                action = "traffic_steering"
                reasoning = "Borderline metrics - insufficient data for confident recommendation"
            
            scenario['ai_analysis'] = {
                "action": action,
                "confidence": confidence,
                "reasoning": reasoning
            }
        
        return scenarios
    
    def check_safety_approval(self, confidence: float) -> dict:
        """Check if action meets safety threshold"""
        auto_execute = confidence >= self.CONFIDENCE_THRESHOLD
        
        return {
            "auto_execute": auto_execute,
            "threshold": self.CONFIDENCE_THRESHOLD,
            "confidence": confidence,
            "status": "AUTO_APPROVED" if auto_execute else "HUMAN_APPROVAL_REQUIRED",
            "safety_check": "PASSED" if auto_execute else "BLOCKED"
        }
    
    def execute_action(self, scenario: dict, safety_approval: dict) -> dict:
        """Execute action based on safety approval"""
        
        if not safety_approval["auto_execute"]:
            return {
                "status": "BLOCKED",
                "reason": f"Confidence {safety_approval['confidence']:.1%} below {safety_approval['threshold']:.1%} threshold",
                "executed": False,
                "requires_human_approval": True,
                "safety_status": "BLOCKED_FOR_SAFETY"
            }
        
        return {
            "status": "EXECUTED",
            "action": scenario["ai_analysis"]["action"],
            "cell_id": scenario["cell_id"],
            "executed": True,
            "safety_status": "AUTO_APPROVED",
            "impact": {
                "utilization_reduction": "25%",
                "energy_savings": "15%",
                "execution_time": "1.2s"
            }
        }

def log_decision(scenario_data, log_file="decision_log.json"):
    """Log decision data to JSON file for audit purposes"""
    log_entry = {
        "timestamp": datetime.datetime.now().isoformat(),
        "demo_run": True,
        **scenario_data
    }
    
    # Load existing log or create new
    if os.path.exists(log_file):
        try:
            with open(log_file, 'r') as f:
                content = f.read().strip()
                logs = json.loads(content) if content else []
        except (json.JSONDecodeError, FileNotFoundError):
            logs = []
    else:
        logs = []
    
    logs.append(log_entry)
    
    with open(log_file, 'w') as f:
        json.dump(logs, f, indent=2)

def main():
    print("üõ°Ô∏è  AI Safety Mechanisms Demo")
    print("=" * 50)
    print("üéØ Confidence Threshold: 80% for auto-execution")
    print("üîí Below 80% ‚Üí Human approval required")
    print()
    
    demo = MixedSafetyDemo()
    scenarios = demo.load_demo_scenarios()
    
    auto_executed = 0
    human_approval_required = 0
    demo_results = []
    
    for i, scenario in enumerate(scenarios, 1):
        print(f"üìä Scenario {i}: {scenario['cell_id']}")
        print(f"   Latency: {scenario['latency_ms']}ms")
        print(f"   Utilization: {scenario['utilization_pct']}%")
        print(f"   Packet Loss: {scenario['packet_loss']}%")
        
        analysis = scenario["ai_analysis"]
        print(f"\nüß† AI Analysis:")
        print(f"   Action: {analysis['action']}")
        print(f"   Confidence: {analysis['confidence']:.1%}")
        print(f"   Reasoning: {analysis['reasoning']}")
        
        # Safety Check
        safety = demo.check_safety_approval(analysis['confidence'])
        print(f"\nüõ°Ô∏è  Safety Gate:")
        print(f"   Threshold Check: {analysis['confidence']:.1%} vs {safety['threshold']:.1%}")
        print(f"   Decision: {safety['status']}")
        print(f"   Safety Status: {safety['safety_check']}")
        
        # Execution
        execution = demo.execute_action(scenario, safety)
        print(f"\n‚ö° Execution Result:")
        
        # Log decision data
        decision_data = {
            "scenario_id": i,
            "cell_id": scenario['cell_id'],
            "metrics": {
                "latency_ms": scenario['latency_ms'],
                "utilization_pct": scenario['utilization_pct'],
                "packet_loss": scenario['packet_loss']
            },
            "ai_analysis": analysis,
            "safety_check": safety,
            "execution_result": execution
        }
        demo_results.append(decision_data)
        log_decision(decision_data)
        
        if execution['executed']:
            print(f"   ‚úÖ STATUS: {execution['status']}")
            print(f"   ü§ñ Auto-executed by AI system")
            print(f"   üìà Expected Impact:")
            for key, value in execution['impact'].items():
                print(f"      {key.replace('_', ' ').title()}: {value}")
            auto_executed += 1
        else:
            print(f"   ‚ùå STATUS: {execution['status']}")
            print(f"   üö´ {execution['reason']}")
            print(f"   üë§ Human operator approval required")
            print(f"   üìã Action queued for manual review")
            human_approval_required += 1
        
        print("‚îÄ" * 50)
    
    print(f"\nüìà Safety Mechanism Results:")
    print(f"‚úÖ Auto-executed (‚â•80% confidence): {auto_executed}")
    print(f"‚ùå Human approval required (<80%): {human_approval_required}")
    print(f"üõ°Ô∏è  Safety rate: {(human_approval_required/len(scenarios)*100):.0f}% of actions blocked for safety")
    
    print(f"\nüéØ Key Safety Features:")
    print(f"‚Ä¢ Confidence-based execution control")
    print(f"‚Ä¢ 80% threshold prevents risky actions")
    print(f"‚Ä¢ Human oversight for uncertain cases")
    print(f"‚Ä¢ Complete audit trail maintained")
    print(f"‚Ä¢ Critical network operations protected")
    
    print(f"\nüìù Audit Log:")
    print(f"‚Ä¢ {len(demo_results)} decisions logged to decision_log.json")
    print(f"‚Ä¢ Full audit trail available for compliance review")

if __name__ == "__main__":
    main()